# getpara

　initialize.py ---------------------------------------------------------
　　解析の初期化
　　rawdata のパス（DAQ時に入力したoutputフォルダー）、チャンネル、解析用outputフォルダー名を入力
  　その後setting.jsonファイルが更新される

  main.py ----------------------------------------------------------------
    rawdataの解析用
    オプションなしの場合、入力した番号のパルスを表示、setting.jsonのパラメータによる解析結果も表示
    option 
    -a : 全てのパルスを解析
    -t : テストモード　ランダムで任意の長さのrawdataを抽出して解析
    -p : PoST解析用　チャンネル毎のsettingを変えて解析
    -l : lowpass filter
    -f : fitting  時間がかかる

    使用例：python main.py -a -t -p

    解析パラメータはsetting.jsonファイルで変更
    
    "Config": {
          "path": "E:/tsuruta/20230616_post/room1-ch2-3_180mK_570uA_100kHz_g10",　#データパス
          "channel": "0", #解析チャンネル
          "rate": 1000000,　#サンプルレート
          "samples": 100000, #サンプル数/チャンネル
          "presamples": 10000, #トリガー点
          "threshold": 0.05,　# 閾値
          "output": "lpf5000"　#outputフォルダーの名前
      },
      "main": {
          "base_x": 1000, #ベースラインを決めるスタート点　presamples - base_x　を開始地点とする
          "base_w": 500,　#ベースラインを決める幅　base_wの間のサンプルの平均値をベースラインとする
          "peak_max": 1000,　#ピークを決める範囲　presamplesからpeak_maxの幅の範囲内の最大値をピークとする
          "peak_x": 3, #平均ピークをとる幅のスタート地点　peak_maxから-peak_x地点を範囲のスタート地点とする
          "peak_w": 10,　#平均ピークを決める幅　peak_xをスタートとしてpeak_wの幅の範囲内の平均値を平均ピークとする
          "fit_func": "monoExp",　#フィッティングの関数　（monoExpは指数減衰だけ、doubleExpは2項の指数関数の和）
          "fit_x": 5000, #フィッティングに使用するサンプルの開始地点　peak_maxのインデックスからfit_xの点を開始点
          "fit_w": 50000,　#フィッティングの幅　fit_xを開始としてfit_w間のサンプルをフィッティングに使用する
          "fit_p0": [0.1,1e-5], #フィッテイングの初期値　gp.monoExp gp.doubleExpを参考に決める
          "mv_w": 1, #移動平均の幅
          "cutoff": 10000.0　#low pass filter のカットオフ周波数
      },

    全パルス解析（option '-a'）後、output.csvファイルが作成され、
    [number,base,height,peak_index,rise,decay,trig]の解析結果が見れる
    フィッティングモードで解析した場合、
    上記に加えて
    [tau_rise,tau_decay,rAquared]
    が追記される

    補足
    height ピークの平均値　
    peak_index　ピークの場所、
    rise 立ち上がりの10%から90％まで時間
    decay 立下りの10%から90％まで時間
    trig　トリガーチャンネル
    tau_rise doubleExpでフィッティングしたときの立ち上がりの時定数
    tau_decay 立下がりの時定数
    rSquard　フィッティング誤差


　selectdata.py----------------------------------------------------------------
　　解析結果をプロットする。オプション必須。
  オプションにプロットの軸を入力
  軸はoutput.csvのcolumn値ならなんでもよい（１つ目に入力したものがｘ軸、２つ目がy軸になる）
  使用例： python selectdata.py rise height

  option 
  '-p' PoSTモード　セレクトモードで選択したデータをもう片チャンネルのプロットでも表示する


  １．normalモード  
  実行後、プロットされる。（このグラフはただプロットするだけ、保存もされる）
  グラフを閉じると、中止の選択が提示されるが、終了する場合’１’を入力
  終了しない場合、そのままEnterキーを押すとデータセレクトモードに移行する

  ２．selectモード
  プロット中の任意のデータを抽出してそのnumberと平均パルスを取得する
．
  選択データ用のoutputファイル名を入力
  plotを任意の点で囲むと囲んだ範囲内のデータを取得することができる
　囲み方
　左クリックで点を打つ、右クリックで点を消去、ホイールクリックで決定
　決定後、選択範囲のデータを色付けしたプロットを表示
　セレクトデータの画像ファイル、インデックスファイルがoutputファイルに出力
  その後、deleteモードへ移行する

  ３．deleteモード
  画像ファイルのファイルダイアログが表示されるので、ノイズデータと思われるデータを選択
  複数選択可能で、ctrキーを押しながら選択する（離した状態で押すとリセットされるので注意）
  deleteモードで選択したデータはselectモードで選択データしたデータリストから除外され、またoutput.csvファイルに除外したデータにのみ０値が与えられる。（ノイズデータを除去するのに貢献）

  ４．平均パルス作成モード
  選択したデータから平均パルスを作成する。同時にログプロットも作成


  データクリーニング
  プロット時に、条件によって表示するデータを制限することができる
  setting.jsonファイルのselect項から条件を指定
  条件は軸に使用するパラメータから選択
  書き方　（例）：
  "base->":0  #base>0
  "samples-=":100000  #samples == 100000
  "number->":10000 #10000番目以降のデータだけを抽出






  　

    
   
